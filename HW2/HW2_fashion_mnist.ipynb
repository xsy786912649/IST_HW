{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3908,"status":"ok","timestamp":1644275704495,"user":{"displayName":"Siyuan Xu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02533286040223950786"},"user_tz":300},"id":"v0hRDnJGY3bH"},"outputs":[],"source":["import os\n","import numpy as np\n","import time\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import matplotlib\n","import math"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1644275704496,"user":{"displayName":"Siyuan Xu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02533286040223950786"},"user_tz":300},"id":"cNjPazCLXvG8","outputId":"e8b779e7-1d19-4903-be9a-4f38225b8c1d"},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["tf.executing_eagerly()\n","tf.config.list_physical_devices('GPU')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2115,"status":"ok","timestamp":1644275706606,"user":{"displayName":"Siyuan Xu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02533286040223950786"},"user_tz":300},"id":"usm43hiZX5AN","outputId":"d28ce3fd-b936-4f32-f7ed-eaf45ac8fb02"},"outputs":[{"name":"stdout","output_type":"stream","text":["(60000, 28, 28)\n","(60000,)\n","(10000, 28, 28)\n","(10000,)\n","[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0]\n","(60000, 784)\n","(60000,)\n","(10000, 784)\n","(10000,)\n","[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0]\n"]}],"source":["seed=1234\n","np.random.seed(seed)\n","tf.random.set_seed(seed)\n","\n","size_input = 28*28\n","size_hidden_1 = 256\n","size_hidden_2 = 128\n","size_output = 10\n","batch_size=30\n","lr=0.2\n","dropout_p=0.0\n","L1=0.0000\n","L2=0.0000\n","\n","fashion_mnist = tf.keras.datasets.fashion_mnist\n","(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","print(x_train.shape)\n","print(y_train.shape)\n","print(x_test.shape)\n","print(y_test.shape)\n","print(y_test[0:20])\n","x_train=tf.reshape(x_train,[x_train.shape[0],-1])\n","x_test=tf.reshape(x_test,[x_test.shape[0],-1])\n","print(x_train.shape)\n","print(y_train.shape)\n","print(x_test.shape)\n","print(y_test.shape)\n","print(y_test[0:20])"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":203,"status":"ok","timestamp":1644275706804,"user":{"displayName":"Siyuan Xu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02533286040223950786"},"user_tz":300},"id":"alvV40KYMOrK"},"outputs":[],"source":["class MLP(tf.keras.Model):\n","  def __init__(self, size_input, size_hidden_1, size_hidden_2, size_output, device=None):\n","    super(MLP, self).__init__()\n","    \"\"\"\n","    size_input: int, size of input layer\n","    size_hidden: int, size of hidden layer\n","    size_output: int, size of output layer\n","    device: str or None, either 'cpu' or 'gpu' or None. If None, the device to be used will be decided automatically during Eager Execution\n","    \"\"\"\n","\n","    self.size_input, self.size_hidden_1, self.size_hidden_2, self.size_output, self.device =\\\n","    size_input, size_hidden_1, size_hidden_2, size_output, device\n","\n","    self.initial=tf.keras.initializers.he_normal(seed=seed)\n","    \n","    # Initialize weights between input layer and hidden layer\n","    self.W1 = tf.Variable(self.initial([self.size_input, self.size_hidden_1]))\n","    # Initialize biases for hidden layer\n","    self.b1 = tf.Variable(self.initial([1, self.size_hidden_1]))\n","     # Initialize weights between hidden layer and output layer\n","    self.W2 = tf.Variable(self.initial([self.size_hidden_1, self.size_hidden_2]))\n","    # Initialize biases for hidden layer\n","    self.b2 = tf.Variable(self.initial([1, self.size_hidden_2]))\n","     # Initialize weights between hidden layer and output layer\n","    self.W3 = tf.Variable(self.initial([self.size_hidden_2, self.size_output]))\n","    # Initialize biases for output layer\n","    self.b3 = tf.Variable(self.initial([1, self.size_output]))\n","    \n","    # Define variables to be updated during backpropagation\n","    self.MLP_variables = [self.W1, self.b1, self.W2, self.b2, self.W3, self.b3]\n","\n","    self.loss_object =tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","    self.reg_12=tf.keras.regularizers.L1L2(l1=L1, l2=L2)\n","    \n","  def forward(self, training, X):\n","    \"\"\"\n","    forward pass\n","    X: Tensor, inputs\n","    \"\"\"\n","    if training==1:\n","      if self.device is not None:\n","        with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n","          self.y = self.compute_output(X)\n","      else:\n","        self.y = self.compute_output(X)\n","    elif training==0:\n","      if self.device is not None:\n","        with tf.device('gpu:0' if self.device=='gpu' else 'cpu'):\n","          self.y = self.compute_output_test(X)\n","      else:\n","        self.y = self.compute_output_test(X)\n","      \n","    return self.y\n","  \n","  def loss(self, y_pred, y_true):\n","    '''\n","    y_pred - Tensor of shape (batch_size, size_output)\n","    y_true - Tensor of shape (batch_size, size_output)\n","    '''\n","    #y_true_tf = tf.cast(tf.reshape(y_true, (-1, self.size_output)), dtype=tf.float32)\n","    return self.loss_object(y_true, y_pred)+self.reg_12(self.W1)+self.reg_12(self.W2)\n","  \n","  def backward(self, X_train, y_train):\n","    \"\"\"\n","    backward pass\n","    \"\"\"\n","    optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n","    #optimizer = tf.keras.optimizers.Adam()\n","    with tf.GradientTape() as tape:\n","      predicted = self.forward(1,X_train)\n","      current_loss = self.loss(predicted, y_train)\n","    grads = tape.gradient(current_loss, self.MLP_variables)\n","    optimizer.apply_gradients(zip(grads, self.MLP_variables))\n","\n","        \n","  def compute_output(self, X):\n","    \"\"\"\n","    Custom method to obtain output tensor during forward pass\n","    \"\"\"\n","    # Cast X to float32\n","    X_tf = tf.cast(X, dtype=tf.float32)\n","    #Remember to normalize your dataset before moving forward\n","    # Compute values in hidden layer\n","    what = tf.matmul(X_tf, self.W1) + self.b1\n","    hhat = tf.nn.relu(what)\n","    hhat = tf.nn.dropout(hhat, rate = dropout_p, seed = seed)\n","    what_1 = tf.matmul(hhat, self.W2) + self.b2\n","    hhat_1 = tf.nn.relu(what_1)\n","    hhat_1 = tf.nn.dropout(hhat_1, rate = dropout_p, seed = seed)\n","    # Compute output\n","    what_2 = tf.matmul(hhat_1, self.W3) + self.b3\n","    #output= tf.nn.softmax(what_2)\n","    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n","    #Second add tf.Softmax(output) and then return this variable\n","    return what_2\n","\n","  def compute_output_test(self, X):\n","    \"\"\"\n","    Custom method to obtain output tensor during forward pass\n","    \"\"\"\n","    # Cast X to float32\n","    X_tf = tf.cast(X, dtype=tf.float32)\n","    #Remember to normalize your dataset before moving forward\n","    # Compute values in hidden layer\n","    what = tf.matmul(X_tf, self.W1) + self.b1\n","    hhat = tf.nn.relu(what)\n","    what_1 = tf.matmul(hhat, self.W2) + self.b2\n","    hhat_1 = tf.nn.relu(what_1)\n","    # Compute output\n","    what_2 = tf.matmul(hhat_1, self.W3) + self.b3\n","    #output= tf.nn.softmax(what_2)\n","    #Now consider two things , First look at inbuild loss functions if they work with softmax or not and then change this\n","    #Second add tf.Softmax(output) and then return this variable\n","    return what_2\n","  "]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1644275706804,"user":{"displayName":"Siyuan Xu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02533286040223950786"},"user_tz":300},"id":"dWR6xLZ2aabo","outputId":"72904fb1-de95-4f5e-ef33-98768efda114"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[[[1 1 2 2]]\n","\n"," [[3 2 2 3]]], shape=(2, 1, 4), dtype=int32)\n"]},{"data":{"text/plain":["(2, 2, 2)"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["t=np.array([[[1,1],[2,2]],[[3,2],[2,3]]])\n","print(tf.reshape(t,[2,1,-1]))\n","t.shape"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1644275707008,"user":{"displayName":"Siyuan Xu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02533286040223950786"},"user_tz":300},"id":"IcjnKTHNPvGC"},"outputs":[],"source":["# Set number of epochs\n","NUM_EPOCHS = 20"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":64000,"status":"ok","timestamp":1644276488034,"user":{"displayName":"Siyuan Xu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02533286040223950786"},"user_tz":300},"id":"gBaOygw_Px7Z","outputId":"9ef09b6a-7e1c-4c30-ec3d-688db1aa3dee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0, Test Loss: 3.653257131576538, Test Accuracy: 12.050000190734863\n","Epoch 1, Loss: 0.368476927280426, Accuracy: 87.99333190917969, Test Loss: 0.5058491230010986, Test Accuracy: 81.87999725341797\n","Epoch 2, Loss: 0.221223846077919, Accuracy: 92.85166931152344, Test Loss: 0.4344072639942169, Test Accuracy: 84.5\n","Epoch 3, Loss: 0.19239984452724457, Accuracy: 93.89167022705078, Test Loss: 0.3814765512943268, Test Accuracy: 85.98999786376953\n","Epoch 4, Loss: 0.1747613400220871, Accuracy: 94.52000427246094, Test Loss: 0.37567225098609924, Test Accuracy: 86.05999755859375\n","Epoch 5, Loss: 0.1641133725643158, Accuracy: 94.85333251953125, Test Loss: 0.37308743596076965, Test Accuracy: 86.52999877929688\n","Epoch 6, Loss: 0.15412969887256622, Accuracy: 95.29499816894531, Test Loss: 0.37678465247154236, Test Accuracy: 86.5\n","Epoch 7, Loss: 0.1469857543706894, Accuracy: 95.5616683959961, Test Loss: 0.35576561093330383, Test Accuracy: 86.66999816894531\n","Epoch 8, Loss: 0.1395873874425888, Accuracy: 95.83332824707031, Test Loss: 0.3459150195121765, Test Accuracy: 87.51000213623047\n","Epoch 9, Loss: 0.1333150565624237, Accuracy: 96.02666473388672, Test Loss: 0.339163213968277, Test Accuracy: 87.91999816894531\n","Epoch 10, Loss: 0.12689180672168732, Accuracy: 96.21833801269531, Test Loss: 0.38338780403137207, Test Accuracy: 86.77999877929688\n","Epoch 11, Loss: 0.12236598879098892, Accuracy: 96.46833801269531, Test Loss: 0.34809282422065735, Test Accuracy: 87.87000274658203\n","Epoch 12, Loss: 0.11740963906049728, Accuracy: 96.53333282470703, Test Loss: 0.3522546589374542, Test Accuracy: 87.87999725341797\n","Epoch 13, Loss: 0.1135135293006897, Accuracy: 96.66666412353516, Test Loss: 0.334543913602829, Test Accuracy: 88.22000122070312\n","Epoch 14, Loss: 0.1084488108754158, Accuracy: 96.86166381835938, Test Loss: 0.35192427039146423, Test Accuracy: 88.05999755859375\n","Epoch 15, Loss: 0.1054043397307396, Accuracy: 96.98500061035156, Test Loss: 0.38426628708839417, Test Accuracy: 86.87999725341797\n","Epoch 16, Loss: 0.1017296314239502, Accuracy: 97.09333038330078, Test Loss: 0.3633438050746918, Test Accuracy: 88.02999877929688\n","Epoch 17, Loss: 0.09680727869272232, Accuracy: 97.28833770751953, Test Loss: 0.3859633803367615, Test Accuracy: 87.30999755859375\n","Epoch 18, Loss: 0.09631597995758057, Accuracy: 97.29000091552734, Test Loss: 0.3559994399547577, Test Accuracy: 88.61000061035156\n","Epoch 19, Loss: 0.09111275523900986, Accuracy: 97.47833251953125, Test Loss: 0.3577461540699005, Test Accuracy: 88.20000457763672\n","Epoch 20, Loss: 0.08802367001771927, Accuracy: 97.5616683959961, Test Loss: 0.367297500371933, Test Accuracy: 88.01000213623047\n","\n","Total time taken (in seconds): 537.42\n"]}],"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n","\n","train_loss.reset_states()\n","train_accuracy.reset_states()\n","test_loss.reset_states()\n","test_accuracy.reset_states()\n","\n","mlp_on_default = MLP(size_input, size_hidden_1, size_hidden_2, size_output)\n","\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\n","train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(10000, seed=seed).batch(batch_size)\n","\n","for inputs, outputs in test_ds:\n","  preds = mlp_on_default.forward(0,inputs)\n","  test_loss(mlp_on_default.loss(preds,outputs))\n","  test_accuracy(outputs, preds)\n","\n","print(\n","  f'Epoch {0}, '\n","  f'Test Loss: {test_loss.result()}, '\n","  f'Test Accuracy: {test_accuracy.result() * 100}'\n",")\n","\n","time_start = time.time()\n","for epoch in range(NUM_EPOCHS):\n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_loss.reset_states()\n","  test_accuracy.reset_states()\n","  \n","  for inputs, outputs in train_ds:\n","    mlp_on_default.backward(inputs, outputs)\n","    preds = mlp_on_default.forward(0,inputs)\n","    train_loss(mlp_on_default.loss(preds,outputs))\n","    train_accuracy(outputs, preds)\n","\n","  for inputs, outputs in test_ds:\n","    preds = mlp_on_default.forward(0,inputs)\n","    test_loss(mlp_on_default.loss(preds,outputs))\n","    test_accuracy(outputs, preds)\n","  \n","  print(\n","    f'Epoch {epoch + 1}, '\n","    f'Loss: {train_loss.result()}, '\n","    f'Accuracy: {train_accuracy.result() * 100}, '\n","    f'Test Loss: {test_loss.result()}, '\n","    f'Test Accuracy: {test_accuracy.result() * 100}'\n","  )\n","\n","time_taken = time.time() - time_start\n","\n","print('\\nTotal time taken (in seconds): {:.2f}'.format(time_taken))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1644276488296,"user":{"displayName":"Siyuan Xu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02533286040223950786"},"user_tz":300},"id":"zjEJImTJ9sQU"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"HW2_fashion_mnist.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
